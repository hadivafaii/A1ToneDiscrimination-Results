
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Autoencoders &#8212; A1 Tone Discrimination</title>
    
  <link rel="stylesheet" href="_static/css/index.73d71520a4ca3b99cfee5594769eaaae.css">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="_static/sphinx-book-theme.2d2078699c18a0efb88233928e1cf6ed.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="_static/js/index.3da636dd464baa7582d2.js">

    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/language_data.js"></script>
    <script src="_static/togglebutton.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/sphinx-book-theme.be0a4a0c39cd630af62a2fcf693f3f06.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="Section 2" href="sec2.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="index.html">
  
  <img src="_static/logo.png" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">A1 Tone Discrimination</h1>
  
</a>
</div>

<form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>

<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="intro.html">
   Welcome
  </a>
 </li>
</ul>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="sec1.html">
   Section 1
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="reference internal" href="sec2.html">
   Section 2
  </a>
  <ul class="current">
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Autoencoders
    </a>
   </li>
  </ul>
 </li>
</ul>

</nav>

 <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        <div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    
    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="_sources/ae_crap.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
    
</div>
        <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/hadivafaii/A1ToneDiscrimination"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/hadivafaii/A1ToneDiscrimination/issues/new?title=Issue%20on%20page%20%2Fae_crap.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/hadivafaii/A1ToneDiscrimination/master?urlpath=tree/docs/ae_crap.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#architecture">
   Architecture
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#embedding-layer">
     embedding layer
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#encoder-network">
     encoder network
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#decoder-network">
     decoder network
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#model-sketch">
   Model sketch
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#performance">
     Performance
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#inspecting-the-model">
     Inspecting the model
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#a-big-flaw">
       A big flaw:
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#plotting-the-latents">
     Plotting the latents
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#do-latents-look-different-for-different-trial-types">
     Do latents look different for different trial types?
    </a>
   </li>
  </ul>
 </li>
</ul>

        </nav>
        
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="autoencoders">
<h1>Autoencoders<a class="headerlink" href="#autoencoders" title="Permalink to this headline">¶</a></h1>
<p>Goal: build a model that achieves a general “understanding” of the data within a latent variable framework. This understanding can be measured using variance explained and also behavior prediction accuracy score. Within a latent variable modeling framework, we assume thta the observed data <span class="math notranslate nohighlight">\(X\)</span> is essentially low dimensional and it can be explained using a few latent variables <span class="math notranslate nohighlight">\(Z\)</span>.  Formally, this can be expressed as follows:</p>
<div class="math notranslate nohighlight">
\[P(X) = \int P(X, Z) dZ = \int P(X | Z) P(Z) dZ,\]</div>
<p>where X is all observed modalities including neural activity and licking data.  We already have some validation and reasons to belive that this is a good assumption.  For example the LDA analysis showed us that we can obtain diverging trajectories in dimensions as low as 2, while maintaining discriminatory power.</p>
<p>If succesful, we can learn something about dimensionality of the data.  Also, hopefully we will be able to identify different sources of variation and see which of those are more correlated with the behavior.</p>
<div class="section" id="architecture">
<h2>Architecture<a class="headerlink" href="#architecture" title="Permalink to this headline">¶</a></h2>
<p>So far, I have only experimented with the simplest possible model.  It includes the following layers:</p>
<div class="section" id="embedding-layer">
<h3>embedding layer<a class="headerlink" href="#embedding-layer" title="Permalink to this headline">¶</a></h3>
<p>this layer takes data from different experiments and maps it to a space with shared dimensionality.  This is to circumvent the the mismatch in number of neurons in different experiments that was preventing us from mixing them together.  For example, if the hiddent shared dimension is 64, then the weights in this layer for experiment <span class="math notranslate nohighlight">\(i\)</span> with <span class="math notranslate nohighlight">\(nc_i\)</span> cells will have shape <span class="math notranslate nohighlight">\(nc_i \times 64\)</span> and so on.  It has distinct weights for each experiment since they have different number of neurons and they are ordered arbitrarily.</p>
<p>What does this 64 dimensional space mean?  One way of looking at it is to assume there are some abstract patterns in neural population code that encode some specific event, and these events will be represented in a different way in each experiment.  One implicit assumption here is that such patterns are more or less present in different experiments, despite having different number of neurons from different subjects.  The goal of the embedding layer is to identify and encode such patterns.</p>
</div>
<div class="section" id="encoder-network">
<h3>encoder network<a class="headerlink" href="#encoder-network" title="Permalink to this headline">¶</a></h3>
<p>Receives the output of embedding layer, now shared across experiments, as input.  Right now I’m using a single linear layer with 16 dimensions, followed by a nonlinearity.  This is an extremely limited choice.  There are lots of things one can try as an encoder network.  For example, one might add recurrence that captures evolving temporal patterns rather than instantanous patterns.  The 1-layer encoder right now is treating every timepoint as if they are identical, which is very wrong.</p>
</div>
<div class="section" id="decoder-network">
<h3>decoder network<a class="headerlink" href="#decoder-network" title="Permalink to this headline">¶</a></h3>
<p>Just like encoder, this is also a 1-layer network followed by a nonlinearity.  Its output is fed into the transpose of the embedding layer, which aims to reconstruct the inputs.  The decoder also does not take into account time for now.</p>
</div>
</div>
<div class="section" id="model-sketch">
<h2>Model sketch<a class="headerlink" href="#model-sketch" title="Permalink to this headline">¶</a></h2>
<p>Here is a high level illustration.  The key for a succesfull model will be a clever encoder and decoder design that respects the data structure and also temporal dynamics, both local and global scales. Decoding behavior labels and stim labels form latents will make them learn signals that are correlated to both, either one, or none of these labels (I will provide more details on this when I implemented it).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">IFrame</span>
<span class="n">IFrame</span><span class="p">(</span><span class="s1">&#39;./sketch.pdf&#39;</span><span class="p">,</span> <span class="n">embed</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">700</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
<iframe
    width="700"
    height="500"
    src="./sketch.pdf?embed=True"
    frameborder="0"
    allowfullscreen
></iframe>
</div></div>
</div>
<div class="section" id="performance">
<h3>Performance<a class="headerlink" href="#performance" title="Permalink to this headline">¶</a></h3>
<p>Here I will load a sample autoencoder and plot how the latents look like.  This model has</p>
<ul class="simple">
<li><p>hidden shared dim = 64 (i.e. for embedding layer), and</p></li>
<li><p>z_dim = 16 (latent dimension)</p></li>
</ul>
<p>The variance explained is quite low, which is understandable given limitations of this architecture.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">datetime</span>
<span class="kn">from</span> <span class="nn">os.path</span> <span class="kn">import</span> <span class="n">join</span> <span class="k">as</span> <span class="n">pjoin</span>
<span class="kn">from</span> <span class="nn">copy</span> <span class="kn">import</span> <span class="n">deepcopy</span> <span class="k">as</span> <span class="n">dc</span>
<span class="kn">from</span> <span class="nn">tqdm.notebook</span> <span class="kn">import</span> <span class="n">tqdm</span>
<span class="kn">import</span> <span class="nn">pickle</span>
<span class="kn">import</span> <span class="nn">h5py</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set_style</span><span class="p">(</span><span class="s1">&#39;white&#39;</span><span class="p">)</span>

<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">,</span> <span class="n">category</span><span class="o">=</span><span class="ne">UserWarning</span><span class="p">)</span>

<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;CUDA_VISIBLE_DEVICES&quot;</span><span class="p">]</span><span class="o">=</span><span class="s2">&quot;1&quot;</span>
<span class="n">github_path</span> <span class="o">=</span> <span class="n">pjoin</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;HOME&#39;</span><span class="p">],</span> <span class="s1">&#39;Dropbox/git/A1ToneDiscrimination/&#39;</span><span class="p">)</span>
<span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">github_path</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">utils.plot_functions</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">autoencoder.model_utils</span> <span class="kn">import</span> <span class="n">print_num_params</span><span class="p">,</span> <span class="n">to_np</span><span class="p">,</span> <span class="n">load_model</span>
<span class="kn">from</span> <span class="nn">autoencoder.configuration</span> <span class="kn">import</span> <span class="n">FeedForwardConfig</span><span class="p">,</span> <span class="n">TrainConfig</span>
<span class="kn">from</span> <span class="nn">autoencoder.training</span> <span class="kn">import</span> <span class="n">AETrainer</span><span class="p">,</span> <span class="n">CLFTrainer</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cm</span> <span class="o">=</span> <span class="s1">&#39;tae_h:64_z:16_drp:0.2_wd:0.01_lr:0.001_gamma:0.99&#39;</span>
<span class="n">mod</span><span class="p">,</span> <span class="n">metadata</span> <span class="o">=</span> <span class="n">load_model</span><span class="p">(</span><span class="n">keyword</span><span class="o">=</span><span class="n">cm</span><span class="p">,</span> <span class="n">chkpt_id</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">trainer</span> <span class="o">=</span> <span class="n">AETrainer</span><span class="p">(</span><span class="n">mod</span><span class="p">,</span> <span class="n">TrainConfig</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>warning karl_2018-09-20
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>warning ken_2016-09-23
warning rodger_2017-08-22
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>warning scabbers_2016-08-24
warning scabbers_2016-09-07
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">metadata</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;model_name&#39;: &#39;tae_h:64_z:16_drp:0.2_wd:0.01_lr:0.001_gamma:0.99_8374897185934529168&#39;,
 &#39;chkpt&#39;: 300}
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">output</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">validate</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>valid loss: 7098.274,   valid r2 score:  21.36 %
</pre></div>
</div>
</div>
</div>
<p>We can explain only ~20% of variance</p>
</div>
<div class="section" id="inspecting-the-model">
<h3>Inspecting the model<a class="headerlink" href="#inspecting-the-model" title="Permalink to this headline">¶</a></h3>
<p>Let us compare model predicted traces with the true data for the best and worst cells</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">max_r2</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">([</span>
    <span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span> <span class="n">tr</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">x</span><span class="p">)],</span> <span class="n">pr</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">x</span><span class="p">)])</span>
    <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">tr</span><span class="p">,</span> <span class="n">pr</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="s1">&#39;r2s&#39;</span><span class="p">],</span> <span class="n">output</span><span class="p">[</span><span class="s1">&#39;trues&#39;</span><span class="p">],</span> <span class="n">output</span><span class="p">[</span><span class="s1">&#39;preds&#39;</span><span class="p">])],</span>
    <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">tup</span><span class="p">:</span> <span class="n">tup</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">min_r2</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">([</span>
    <span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">tr</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">x</span><span class="p">)],</span> <span class="n">pr</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">x</span><span class="p">)])</span>
    <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">tr</span><span class="p">,</span> <span class="n">pr</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="s1">&#39;r2s&#39;</span><span class="p">],</span> <span class="n">output</span><span class="p">[</span><span class="s1">&#39;trues&#39;</span><span class="p">],</span> <span class="n">output</span><span class="p">[</span><span class="s1">&#39;preds&#39;</span><span class="p">])],</span>
    <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">tup</span><span class="p">:</span> <span class="n">tup</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">f</span><span class="p">,</span> <span class="n">ax_arr</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>

<span class="n">r2</span><span class="p">,</span> <span class="n">true</span><span class="p">,</span> <span class="n">pred</span> <span class="o">=</span> <span class="n">max_r2</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">ax_arr</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">true</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;true&#39;</span><span class="p">)</span>
<span class="n">ax_arr</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;pred&#39;</span><span class="p">)</span>
<span class="n">ax_arr</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;explained variance: </span><span class="si">{:.1f}</span><span class="s1"> </span><span class="si">{:s}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">r2</span><span class="p">,</span> <span class="s1">&#39;%&#39;</span><span class="p">))</span>
<span class="n">ax_arr</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="n">r2</span><span class="p">,</span> <span class="n">true</span><span class="p">,</span> <span class="n">pred</span> <span class="o">=</span> <span class="n">min_r2</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">ax_arr</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">true</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;true&#39;</span><span class="p">)</span>
<span class="n">ax_arr</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;pred&#39;</span><span class="p">)</span>
<span class="n">ax_arr</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;explained variance: </span><span class="si">{:.1f}</span><span class="s1"> </span><span class="si">{:s}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">r2</span><span class="p">,</span> <span class="s1">&#39;%&#39;</span><span class="p">))</span>
<span class="n">ax_arr</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/ae_crap_13_0.png" src="_images/ae_crap_13_0.png" />
</div>
</div>
<div class="section" id="a-big-flaw">
<h4>A big flaw:<a class="headerlink" href="#a-big-flaw" title="Permalink to this headline">¶</a></h4>
<p>The model predicts some cells perfectly, but other cells no better than chance.  I think I know why: if we look at the variance of the cell itself, we see that the one with almost perfect prediction has a large variance.  Why is this happening?  My guess is because this model is designed poorly and not properly constrained, it is choosing some high variance neurons and assigns some of the latent dimensions to just memorize that neuron.  This way, the model can achieve a lower mean-squared error.  I don’t blame the model for showing this behavior.  Given the current setup, it is really constly to wrongly predict a high variacne neuron, but missing some low variance cells isn’t as bad.</p>
<p>Possible solutions:</p>
<ul class="simple">
<li><p>normalize the loss using input variance. This way, the model will assign equal weight to different neurons and will learn a better latent code.  This isn’t going to help us a lot, but i’m curious how this will affect the overall performance so will try this first</p></li>
<li><p>then, the best strategy is to forget about this architecture and move on to a more constrained model which respects the temporal aspect of the data as well.  The fact that this simple autoencoder failed so badly means there is a nice challenge to address here. We can still use this model for benchmarking purposes.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">r2</span><span class="p">,</span> <span class="n">true</span><span class="p">,</span> <span class="n">pred</span> <span class="o">=</span> <span class="n">max_r2</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">msg1</span> <span class="o">=</span> <span class="s2">&quot;best predicted neuron:</span><span class="se">\n</span><span class="s2">r2 = </span><span class="si">{:.1f}</span><span class="s2"> </span><span class="si">{:s}</span><span class="se">\n</span><span class="s2">trace var: </span><span class="si">{:.2f}</span><span class="s2">&quot;</span>
<span class="n">msg1</span> <span class="o">=</span> <span class="n">msg1</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">r2</span><span class="p">,</span> <span class="s1">&#39;%&#39;</span><span class="p">,</span> <span class="n">true</span><span class="o">.</span><span class="n">var</span><span class="p">())</span>

<span class="n">r2</span><span class="p">,</span> <span class="n">true</span><span class="p">,</span> <span class="n">pred</span> <span class="o">=</span> <span class="n">min_r2</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">msg2</span> <span class="o">=</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">worst predicted neuron:</span><span class="se">\n</span><span class="s2">r2 = </span><span class="si">{:.1f}</span><span class="s2"> </span><span class="si">{:s}</span><span class="se">\n</span><span class="s2">trace var: </span><span class="si">{:.2f}</span><span class="s2">&quot;</span>
<span class="n">msg2</span> <span class="o">=</span> <span class="n">msg2</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">r2</span><span class="p">,</span> <span class="s1">&#39;%&#39;</span><span class="p">,</span> <span class="n">true</span><span class="o">.</span><span class="n">var</span><span class="p">())</span>

<span class="nb">print</span><span class="p">(</span><span class="n">msg1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">msg2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>best predicted neuron:
r2 = 99.4 %
trace var: 4504.06

worst predicted neuron:
r2 = 0.0 %
trace var: 8.24
</pre></div>
</div>
</div>
</div>
<p>This is really bad. A proper autoencoder should not learn to memorize the input data, but rather, detect patterns.</p>
</div>
</div>
<div class="section" id="plotting-the-latents">
<h3>Plotting the latents<a class="headerlink" href="#plotting-the-latents" title="Permalink to this headline">¶</a></h3>
<p>let’s just plot 5 and see how they look like</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="s1">&#39;latents&#39;</span><span class="p">][</span><span class="n">i</span><span class="p">],</span> <span class="n">aspect</span><span class="o">=</span><span class="mf">0.06</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;time&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;z&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/ae_crap_21_0.png" src="_images/ae_crap_21_0.png" />
<img alt="_images/ae_crap_21_1.png" src="_images/ae_crap_21_1.png" />
<img alt="_images/ae_crap_21_2.png" src="_images/ae_crap_21_2.png" />
<img alt="_images/ae_crap_21_3.png" src="_images/ae_crap_21_3.png" />
<img alt="_images/ae_crap_21_4.png" src="_images/ae_crap_21_4.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">latents</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">z</span> <span class="ow">in</span> <span class="n">output</span><span class="p">[</span><span class="s1">&#39;latents&#39;</span><span class="p">]])</span>
<span class="n">latents</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(763, 135, 16)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="s1">&#39;labels&#39;</span><span class="p">])</span>
<span class="n">labels</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(763,)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dict_list</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">z</span><span class="p">,</span> <span class="n">lbl</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="s1">&#39;latents&#39;</span><span class="p">],</span> <span class="n">output</span><span class="p">[</span><span class="s1">&#39;labels&#39;</span><span class="p">]):</span>
    <span class="n">nt</span><span class="p">,</span> <span class="n">k</span> <span class="o">=</span> <span class="n">z</span><span class="o">.</span><span class="n">shape</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">k</span><span class="p">):</span>
        <span class="n">data_dict</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s1">&#39;timepoint&#39;</span><span class="p">:</span> <span class="nb">range</span><span class="p">(</span><span class="n">nt</span><span class="p">),</span>
            <span class="s1">&#39;label&#39;</span><span class="p">:</span> <span class="p">[</span><span class="n">lbl</span><span class="p">]</span> <span class="o">*</span> <span class="n">nt</span><span class="p">,</span>
            <span class="s1">&#39;dim&#39;</span><span class="p">:</span> <span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">nt</span><span class="p">,</span>
            <span class="s1">&#39;z&#39;</span><span class="p">:</span> <span class="n">z</span><span class="p">[:,</span> <span class="n">i</span><span class="p">],</span>
        <span class="p">}</span>
        <span class="n">dict_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">data_dict</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">utils.generic_utils</span> <span class="kn">import</span> <span class="n">merge_dicts</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="o">.</span><span class="n">from_dict</span><span class="p">(</span><span class="n">merge_dicts</span><span class="p">(</span><span class="n">dict_list</span><span class="p">))</span>
<span class="n">df</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>...merging dicts: 0it [00:00, ?it/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>...merging dicts: 43652it [00:00, 436503.76it/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(1648080, 4)
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="do-latents-look-different-for-different-trial-types">
<h3>Do latents look different for different trial types?<a class="headerlink" href="#do-latents-look-different-for-different-trial-types" title="Permalink to this headline">¶</a></h3>
<p>The resemble the traces obtained by simply averaging traces for different behavior types.  This is another sign that this model is not good, because it is expected to capture much more than this.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sns</span><span class="o">.</span><span class="n">relplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s1">&#39;timepoint&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">&#39;z&#39;</span><span class="p">,</span> <span class="n">col</span><span class="o">=</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s1">&#39;dim&#39;</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="s2">&quot;line&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;seaborn.axisgrid.FacetGrid at 0x7f0ec6112c10&gt;
</pre></div>
</div>
<img alt="_images/ae_crap_29_1.png" src="_images/ae_crap_29_1.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sns</span><span class="o">.</span><span class="n">relplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s1">&#39;timepoint&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">&#39;z&#39;</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="n">col</span><span class="o">=</span><span class="s1">&#39;dim&#39;</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="s2">&quot;line&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;seaborn.axisgrid.FacetGrid at 0x7f0ec05b0250&gt;
</pre></div>
</div>
<img alt="_images/ae_crap_30_1.png" src="_images/ae_crap_30_1.png" />
</div>
</div>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="sec2.html" title="previous page">Section 2</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Hadi Vafaii<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="_static/js/index.3da636dd464baa7582d2.js"></script>


    
  </body>
</html>